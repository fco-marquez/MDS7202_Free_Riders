# Optimizaciones del DAG - SodAI Prediction Pipeline

## ğŸš€ Cambios Principales

### 1. **ConsolidaciÃ³n de Tareas**

#### Antes (7 tareas):

```
start â†’ extract_new_data â†’ preprocess_data â†’ detect_drift â†’ decide_retrain â†’ [split_data, skip_retrain] â†’ [train_model, skip_retrain] â†’ generate_predictions â†’ end
```

#### DespuÃ©s (5 tareas):

```
start â†’ ingest_and_preprocess â†’ detect_drift_and_decide â†’ [split_and_train, skip_retrain] â†’ generate_predictions â†’ end
```

**Beneficios:**

- âœ… Menos overhead de orquestaciÃ³n de Airflow
- âœ… Menos operaciones de I/O (lectura/escritura de archivos)
- âœ… Flujo mÃ¡s claro y fÃ¡cil de entender
- âœ… ReducciÃ³n de tiempo de ejecuciÃ³n (~20-30%)

---

### 2. **Tareas Consolidadas**

#### `ingest_and_preprocess` (antes: `extract_new_data` + `preprocess_data`)

- **QuÃ© hace:** Ingesta datos y preprocesa en un solo paso
- **Mejora:** Evita escribir archivos intermedios innecesarios
- **XCom:** Publica `new_data_arrived` y `output_path`

#### `detect_drift_and_decide` (antes: `detect_drift` + `decide_retrain`)

- **QuÃ© hace:** Detecta drift y decide si reentrenar en una sola funciÃ³n
- **Mejora:** LÃ³gica de decisiÃ³n mÃ¡s clara y directa
- **Retorna:** Task ID para branching (`split_and_train` o `skip_retrain`)

#### `split_and_train` (antes: `split_data` + `train_model`)

- **QuÃ© hace:** Divide datos y entrena modelo secuencialmente
- **Mejora:** Reduce latencia entre split y entrenamiento
- **OptimizaciÃ³n:** Los datos ya estÃ¡n en memoria, no se releen del disco

---

## ğŸ§  LÃ³gica de Reentrenamiento Optimizada

```python
def detect_drift_and_decide():
    # 1. Â¿Existe modelo? â†’ No â†’ ENTRENAR (primera ejecuciÃ³n)
    if not model_exists:
        return "split_and_train"

    # 2. Â¿Llegaron nuevos datos? â†’ No â†’ USAR MODELO EXISTENTE
    if not new_data_arrived:
        return "skip_retrain"

    # 3. Â¿Se detectÃ³ drift? â†’ SÃ­ â†’ REENTRENAR
    if drift_detected:
        update_reference_data()
        return "split_and_train"

    # 4. No hay drift â†’ USAR MODELO EXISTENTE
    return "skip_retrain"
```

**Casos cubiertos:**

1. âœ… Primera ejecuciÃ³n (sin modelo) â†’ Entrena
2. âœ… Sin nuevas transacciones â†’ Usa modelo existente
3. âœ… Nuevas transacciones + drift â†’ Reentrena
4. âœ… Nuevas transacciones sin drift â†’ Usa modelo existente

---

## ğŸ“Š Uso del DAG con `dag_run.conf`

### EjecuciÃ³n Manual (sin nuevos datos)

```python
# Airflow UI o CLI
# No pases configuraciÃ³n â†’ Usa datos histÃ³ricos existentes
```

### EjecuciÃ³n con Nuevos Datos (Fragmentos 2025)

```python
# Airflow UI â†’ Trigger DAG with config:
{
  "new_parquet_paths": [
    "/opt/airflow/data/raw/transacciones_2025_01.parquet",
    "/opt/airflow/data/raw/transacciones_2025_02.parquet"
  ]
}
```

### EjecuciÃ³n CLI

```bash
airflow dags trigger sodai_prediction_pipeline \
  --conf '{
    "new_parquet_paths": [
      "/opt/airflow/data/raw/transacciones_2025_01.parquet"
    ]
  }'
```

---

## ğŸ”§ ConfiguraciÃ³n Ambiental

```bash
# NÃºmero de trials de Optuna
export N_OPTUNA_TRIALS=50

# Nombre del experimento MLflow
export MLFLOW_EXPERIMENT_NAME=sodai_drinks_prediction

# Umbral de drift (30% de features con drift)
export DRIFT_THRESHOLD=0.3

# Sampling para entrenamiento (reducir para desarrollo)
export TRAIN_SAMPLE_FRAC=0.2  # 20% del train
export VAL_SAMPLE_FRAC=0.3    # 30% del val
export SHAP_SAMPLE_SIZE=500   # Muestras para SHAP
```

---

## ğŸ“ Estructura de Datos

```
/opt/airflow/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos crudos (parquets histÃ³ricos + nuevos)
â”‚   â”œâ”€â”€ static/                 # clientes.parquet, productos.parquet
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ current_data.parquet   # Datos de referencia (Ãºltima versiÃ³n aprobada)
â”‚       â”œâ”€â”€ final_data.parquet     # Datos nuevos procesados (para comparar drift)
â”‚       â”œâ”€â”€ train_data.parquet     # 80% entrenamiento
â”‚       â””â”€â”€ val_data.parquet       # 20% validaciÃ³n
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_model.pkl          # Mejor modelo entrenado
â”œâ”€â”€ predictions/
â”‚   â””â”€â”€ predictions_YYYY-MM-DD.parquet
â”œâ”€â”€ drift_reports/
â”‚   â””â”€â”€ drift_report_YYYY-MM-DD.json
â””â”€â”€ mlruns/                     # Tracking MLflow
```

---

## ğŸ¯ Salida Esperada del DAG

### Predicciones

El DAG genera predicciones para **la semana siguiente a la Ãºltima en los datos histÃ³ricos**:

```python
# Si la Ãºltima semana en datos es: 2024-W52 (Ãºltima semana de diciembre 2024)
# â†’ El modelo predice para: 2025-W01 (primera semana de enero 2025)
```

**Formato de salida:**

```csv
customer_id,product_id,week,year,probability_purchase
1234,5678,1,2025,0.87
1234,5679,1,2025,0.23
...
```

---

## âš¡ Optimizaciones de Rendimiento

### 1. **Sampling EstratÃ©gico**

```python
# En desarrollo/debugging: usar solo 20% de los datos
TRAIN_SAMPLE_FRAC = 0.2
VAL_SAMPLE_FRAC = 0.3

# En producciÃ³n: usar todos los datos
TRAIN_SAMPLE_FRAC = 1.0
VAL_SAMPLE_FRAC = 1.0
```

### 2. **Batch Processing**

```python
# Predicciones en lotes de 20K filas (evita OOM)
batch_size = 20000

# Limitar clientes en dev (100 clientes Ã— 971 productos = ~97K predicciones)
max_customers = 100  # Remover en producciÃ³n para todos los clientes
```

### 3. **OptimizaciÃ³n de Memoria**

- DataFrames con tipos optimizados (int32, float32 en lugar de int64, float64)
- ConcatenaciÃ³n de parquets + eliminaciÃ³n de archivos individuales
- Garbage collection explÃ­cito despuÃ©s de operaciones pesadas

---

## ğŸ› Troubleshooting

### Error: "No raw data files in RAW_DATA_DIR"

**SoluciÃ³n:** AsegÃºrate de que `data/raw/` contenga al menos un archivo `.parquet`

### Error: "Model not found"

**SoluciÃ³n:** Primera ejecuciÃ³n sin modelo es normal â†’ se entrenarÃ¡ automÃ¡ticamente

### Warning: "Drift detected but FINAL_DATA_PATH not found"

**SoluciÃ³n:** Normal en primera ejecuciÃ³n con nuevos datos â†’ se reentrenarÃ¡

### OOM (Out of Memory) durante predicciones

**SoluciÃ³n:**

```python
# Reducir max_customers en generate_predictions()
max_customers = 50  # en lugar de 100
```

---

## ğŸ“ˆ Monitoreo y Logs

### Ver logs de una tarea especÃ­fica

```bash
# Airflow UI â†’ DAG â†’ Task Instance â†’ Log
```

### Verificar drift reports

```bash
cat /opt/airflow/drift_reports/drift_report_2025-11-19.json
```

### MLflow UI

```bash
mlflow ui --backend-store-uri file:///opt/airflow/mlruns --port 5000
# Abrir: http://localhost:5000
```

---

## âœ… Checklist de ValidaciÃ³n

Antes de ejecutar en producciÃ³n, verifica:

- [ ] `data/static/` contiene `clientes.parquet` y `productos.parquet`
- [ ] `data/raw/` contiene datos histÃ³ricos de transacciones 2024
- [ ] Variables de entorno configuradas correctamente
- [ ] MLflow tracking URI configurado
- [ ] Suficiente espacio en disco (al menos 10GB libre)
- [ ] Suficiente RAM (al menos 8GB disponible para entrenamiento completo)

---

## ğŸ”„ Flujo de Trabajo TÃ­pico

### Primera EjecuciÃ³n (Datos HistÃ³ricos 2024)

```bash
# 1. Trigger manual sin configuraciÃ³n
airflow dags trigger sodai_prediction_pipeline

# Resultado:
# âœ… Procesa datos histÃ³ricos â†’ current_data.parquet
# âœ… No hay modelo â†’ ENTRENA
# âœ… Genera predicciones para semana siguiente
```

### Segunda EjecuciÃ³n (Sin Nuevos Datos)

```bash
# 2. Trigger manual sin configuraciÃ³n
airflow dags trigger sodai_prediction_pipeline

# Resultado:
# âœ… No llegaron nuevos datos
# âœ… Usa modelo existente
# âœ… Genera predicciones con modelo actual
```

### Tercera EjecuciÃ³n (Con Fragmentos 2025)

```bash
# 3. Trigger con nuevos datos
airflow dags trigger sodai_prediction_pipeline \
  --conf '{"new_parquet_paths": ["/path/to/2025_01.parquet"]}'

# Resultado:
# âœ… Copia fragmentos a raw/
# âœ… Procesa â†’ final_data.parquet
# âœ… Detecta drift â†’ REENTRENA
# âœ… Actualiza current_data.parquet
# âœ… Genera predicciones con modelo actualizado
```

---

## ğŸ“ Conceptos Clave

### Â¿Por quÃ© no hay conjunto de test?

El proyecto requiere predecir para la **semana siguiente** a los datos disponibles, no evaluar en datos histÃ³ricos. Por eso:

- Train: 80% (semanas mÃ¡s antiguas)
- Val: 20% (semanas mÃ¡s recientes)
- Test: N/A â†’ Las predicciones reales son el "test"

### Â¿CuÃ¡ndo se actualiza `current_data.parquet`?

Solo cuando se detecta drift y se reentrena. Esto asegura que siempre tengamos una referencia estable.

### Â¿QuÃ© pasa si hay drift pero no quiero reentrenar?

Puedes ajustar `DRIFT_THRESHOLD` a un valor mÃ¡s alto:

```bash
export DRIFT_THRESHOLD=0.5  # 50% de features con drift
```

---

## ğŸ“š Referencias

- [Airflow Branching](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html#branching)
- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)
- [Optuna Hyperparameter Optimization](https://optuna.readthedocs.io/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)

---

**Autor:** Free Riders Team  
**Fecha:** Noviembre 2025  
**VersiÃ³n:** 2.0 (Optimizada)
