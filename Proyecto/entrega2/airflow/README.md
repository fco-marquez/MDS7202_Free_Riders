# SodAI Drinks Prediction Pipeline - Documentaci√≥n Completa

**Equipo:** Free Riders
**Proyecto:** MDS7202 - Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos
**Entrega:** 2 - Pipeline Automatizado con Airflow

---

## üìã Tabla de Contenidos

1. [Descripci√≥n General](#-descripci√≥n-general)
2. [Arquitectura del Pipeline](#-arquitectura-del-pipeline)
3. [Diagrama de Flujo](#-diagrama-de-flujo)
4. [Descripci√≥n de Tareas](#-descripci√≥n-de-tareas)
5. [Detecci√≥n de Drift](#-detecci√≥n-de-drift)
6. [L√≥gica de Reentrenamiento](#-l√≥gica-de-reentrenamiento)
7. [Integraci√≥n con MLflow](#-integraci√≥n-con-mlflow)
8. [Estructura de Archivos](#-estructura-de-archivos)
9. [Instalaci√≥n y Configuraci√≥n](#-instalaci√≥n-y-configuraci√≥n)
10. [Ejecuci√≥n del Pipeline](#-ejecuci√≥n-del-pipeline)
11. [Generaci√≥n de Datos de Prueba](#-generaci√≥n-de-datos-de-prueba)
12. [Resultados y Outputs](#-resultados-y-outputs)
13. [Consideraciones de Producci√≥n](#-consideraciones-de-producci√≥n)

---

## üéØ Descripci√≥n General

Este proyecto implementa un **pipeline automatizado de Machine Learning** utilizando Apache Airflow para predecir las compras de productos por cliente en la pr√≥xima semana. El sistema est√° dise√±ado con visi√≥n de producci√≥n, incluyendo:

- ‚úÖ **Detecci√≥n autom√°tica de drift** en los datos
- ‚úÖ **Reentrenamiento condicional** solo cuando se detecta drift
- ‚úÖ **Optimizaci√≥n de hiperpar√°metros** con Optuna (50 trials)
- ‚úÖ **Tracking de experimentos** con MLflow
- ‚úÖ **Interpretabilidad** con SHAP values
- ‚úÖ **Predicciones automatizadas** para la pr√≥xima semana

### Caracter√≠sticas Principales

| Caracter√≠stica | Descripci√≥n |
|---------------|-------------|
| **Orquestador** | Apache Airflow 3.1.0+ |
| **Modelo** | XGBoost con balanceo de clases |
| **Optimizaci√≥n** | Optuna (50 trials) |
| **Tracking** | MLflow para experimentos y modelos |
| **Interpretabilidad** | SHAP values |
| **Drift Detection** | KS-test (num√©ricos) + Chi-square (categ√≥ricos) |
| **M√©trica Principal** | Recall (detectar compras) |

---

## üèóÔ∏è Arquitectura del Pipeline

El pipeline sigue un flujo modular con branching condicional:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    START    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Extract New Data‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Preprocess Data ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Split Data    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Detect Drift   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Branch ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚îÄ‚îò
        ‚îÇ ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ          ‚îÇ
    ‚ñº          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Train  ‚îÇ  ‚îÇ   Skip   ‚îÇ
‚îÇ Model  ‚îÇ  ‚îÇ Retrain  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ            ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Generate   ‚îÇ
    ‚îÇ Predictions ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ  END   ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Diagrama de Flujo

### Vista del DAG en Airflow UI

![DAG Graph View](assets/dag_graph_view.png)
*Captura del DAG `sodai_prediction_pipeline` en la interfaz de Airflow*

**Nota:** Para generar esta imagen:
1. Accede a Airflow UI: `http://localhost:8080`
2. Navega al DAG `sodai_prediction_pipeline`
3. Click en la pesta√±a "Graph"
4. Toma screenshot y gu√°rdalo en `assets/dag_graph_view.png`

### Flujo de Datos

```mermaid
graph TD
    A[Datos Raw] -->|Limpieza| B[Datos Procesados]
    B -->|Divisi√≥n Temporal| C[Train/Val/Test]
    C -->|An√°lisis Estad√≠stico| D{Drift Detectado?}
    D -->|S√≠ > 30%| E[Optimizaci√≥n Optuna]
    D -->|No| F[Usar Modelo Existente]
    E --> G[Entrenar XGBoost]
    G --> H[Guardar en MLflow]
    H --> I[Generar Predicciones]
    F --> I
    I --> J[Predicciones Semana Siguiente]
```

---

## üìù Descripci√≥n de Tareas

### 1. **start** (EmptyOperator)
- **Prop√≥sito:** Marca el inicio del pipeline
- **Duraci√≥n:** Instant√°neo
- **Outputs:** Ninguno

### 2. **extract_new_data** (PythonOperator)
- **Funci√≥n:** `extract_new_data()`
- **Prop√≥sito:** Validar que existan datos raw para procesar
- **Validaciones:**
  - Verifica existencia del directorio `data/raw/`
  - Confirma presencia de archivos `.parquet`
  - Lista archivos encontrados
- **En Producci√≥n:** Aqu√≠ se descargar√≠an datos de APIs, bases de datos, etc.
- **Outputs:** Logs de validaci√≥n

### 3. **preprocess_data** (PythonOperator)
- **Funci√≥n:** `run_preprocessing_pipeline()`
- **M√≥dulo:** `load_and_preprocess.py`
- **Prop√≥sito:** Limpiar y transformar datos raw
- **Operaciones:**
  1. Carga `clientes.parquet`, `productos.parquet`, `transacciones.parquet`
  2. Limpia transacciones:
     - Elimina duplicados
     - Filtra `items = 0`
     - Convierte items a valores absolutos
  3. Optimiza tipos de datos (int64‚Üíint32, float64‚Üífloat32)
  4. Crea variable temporal `week` (semana del a√±o)
  5. Crea variable objetivo `bought` (1 si hubo compra)
  6. Genera **universo cliente √ó producto √ó semana**
  7. Hace merge con datos de clientes y productos
  8. Rellena `bought=0` para pares sin transacci√≥n
- **Outputs:** `data/processed/final_data.parquet`
- **Duraci√≥n Estimada:** 30-60 segundos

### 4. **split_data** (PythonOperator)
- **Funci√≥n:** `run_data_splitting()`
- **M√≥dulo:** `pipeline.py`
- **Prop√≥sito:** Dividir datos respetando temporalidad
- **Divisi√≥n:**
  - **Train:** 70% (semanas m√°s antiguas)
  - **Validation:** 15% (semanas intermedias)
  - **Test:** 15% (semanas m√°s recientes)
- **Importante:** Divisi√≥n temporal (no aleatoria) para evitar data leakage
- **Outputs:**
  - `data/processed/train_data.parquet`
  - `data/processed/val_data.parquet`
  - `data/processed/test_data.parquet`
- **Duraci√≥n Estimada:** 10-20 segundos

### 5. **detect_drift** (PythonOperator)
- **Funci√≥n:** `run_drift_detection()`
- **M√≥dulo:** `drift_detector.py`
- **Prop√≥sito:** Detectar cambios estad√≠sticos en distribuciones
- **Features Monitoreados:**
  - **Num√©ricas:** size, num_deliver_per_week, recency, frequency, customer_product_share, trend
  - **Categ√≥ricas:** customer_type, brand, category, sub_category, segment, package
- **Tests Estad√≠sticos:**
  - **KS-test** (Kolmogorov-Smirnov) para variables num√©ricas
  - **Chi-square** para variables categ√≥ricas
- **Threshold:** p-value < 0.05 indica drift en una feature
- **Decisi√≥n:** Si >30% de features tienen drift ‚Üí reentrenar
- **Outputs:**
  - Booleano `needs_retrain` (v√≠a XCom)
  - `drift_reports/drift_report_{execution_date}.json`
- **Duraci√≥n Estimada:** 20-40 segundos

### 6. **decide_retrain** (BranchPythonOperator)
- **Funci√≥n:** `decide_retrain()`
- **Prop√≥sito:** Branching decision basado en drift
- **L√≥gica:**
  ```python
  if drift_detected:
      return 'train_model'  # Rama de reentrenamiento
  else:
      return 'skip_retrain'  # Rama de skip
  ```
- **Outputs:** Task ID de siguiente tarea
- **Duraci√≥n:** Instant√°neo

### 7a. **train_model** (PythonOperator) [RAMA CONDICIONAL]
- **Funci√≥n:** `run_full_training()`
- **M√≥dulo:** `train_module.py`
- **Prop√≥sito:** Entrenar modelo completo con optimizaci√≥n
- **Pipeline de Entrenamiento:**

  **Fase 1: Optimizaci√≥n de Hiperpar√°metros (Optuna)**
  - 50 trials de b√∫squeda
  - Espacio de b√∫squeda:
    ```python
    max_depth: [3, 10]
    learning_rate: [0.001, 0.3] (log scale)
    n_estimators: [50, 500]
    min_child_weight: [1, 10]
    gamma: [0, 0.5]
    subsample: [0.6, 1.0]
    colsample_bytree: [0.6, 1.0]
    reg_alpha: [0, 1.0]
    reg_lambda: [0, 1.0]
    ```
  - M√©trica de optimizaci√≥n: **Recall** (clase positiva)
  - Tracking de cada trial en MLflow

  **Fase 2: Entrenamiento del Modelo Final**
  - Modelo: XGBoost Classifier
  - Feature Engineering:
    - Clustering geogr√°fico (KMeans, n=2)
    - Features RFM: recency, frequency, customer_product_share, trend
  - Preprocesamiento:
    - Num√©ricas: Imputation + RobustScaler
    - Categ√≥ricas: Imputation + OneHotEncoder
  - Manejo de desbalanceo: `scale_pos_weight` autom√°tico

  **Fase 3: Evaluaci√≥n e Interpretabilidad**
  - M√©tricas: accuracy, precision, recall, F1, AUC-PR
  - Confusion matrix
  - Precision-Recall curve
  - **SHAP values** (1000 muestras):
    - Summary plot
    - Feature importance plot

  **Fase 4: Persistencia**
  - Guardado en MLflow (modelo + metadata)
  - Guardado local: `models/best_model.pkl`

- **Outputs:**
  - Modelo entrenado en MLflow
  - Archivo `models/best_model.pkl`
  - Gr√°ficos en MLflow
- **Duraci√≥n Estimada:** 15-30 minutos (depende de Optuna trials)

### 7b. **skip_retrain** (EmptyOperator) [RAMA CONDICIONAL]
- **Prop√≥sito:** Placeholder cuando no hay drift
- **Acci√≥n:** Ninguna (usa modelo existente)
- **Duraci√≥n:** Instant√°neo

### 8. **generate_predictions** (PythonOperator)
- **Funci√≥n:** `run_prediction_pipeline()`
- **M√≥dulo:** `predict_module.py`
- **Prop√≥sito:** Generar predicciones para pr√≥xima semana
- **Trigger Rule:** `NONE_FAILED` (se ejecuta siempre que ambas ramas no fallen)
- **Proceso:**
  1. Carga mejor modelo (MLflow o local)
  2. Identifica √∫ltima semana en datos: `max(week)`
  3. Crea universo cliente √ó producto para `week + 1`
  4. Aplica feature engineering
  5. Genera predicciones con probabilidades
  6. Guarda resultados
- **Outputs:**
  - `predictions/predictions_{execution_date}.parquet`
  - Columnas: customer_id, product_id, week, prediction, probability
- **Duraci√≥n Estimada:** 2-5 minutos

### 9. **end** (EmptyOperator)
- **Prop√≥sito:** Marca fin exitoso del pipeline
- **Trigger Rule:** `NONE_FAILED`
- **Duraci√≥n:** Instant√°neo

---

## üîç Detecci√≥n de Drift

### ¬øQu√© es Drift?

El **drift** es el cambio en las distribuciones de los datos a lo largo del tiempo. Puede ocurrir por:
- Cambios en comportamiento de clientes
- Nuevos productos o categor√≠as
- Estacionalidad
- Eventos externos (promociones, pandemias, etc.)

### Implementaci√≥n

**M√≥dulo:** `drift_detector.py`

#### Tests Estad√≠sticos

1. **Kolmogorov-Smirnov (KS) Test** para variables num√©ricas
   - Compara distribuciones de datos hist√≥ricos vs nuevos
   - Hip√≥tesis nula: ambas muestras vienen de la misma distribuci√≥n
   - p-value < 0.05 ‚Üí Rechazamos H‚ÇÄ ‚Üí **Drift detectado**

2. **Chi-Square Test** para variables categ√≥ricas
   - Compara frecuencias de categor√≠as
   - Hip√≥tesis nula: distribuciones son independientes
   - p-value < 0.05 ‚Üí Rechazamos H‚ÇÄ ‚Üí **Drift detectado**

#### Umbrales

```python
KS_THRESHOLD = 0.05      # p-value para KS test
CHI2_THRESHOLD = 0.05    # p-value para Chi-square test
DRIFT_THRESHOLD = 0.3    # 30% de features con drift ‚Üí reentrenar
```

#### Decisi√≥n de Reentrenamiento

```python
if (features_with_drift / total_features) > 0.3:
    needs_retrain = True  # Reentrenar modelo
else:
    needs_retrain = False  # Usar modelo existente
```

### Reporte de Drift

Cada ejecuci√≥n genera un reporte JSON:

```json
{
  "timestamp": "2024-11-05T10:30:00",
  "reference_data_shape": [100000, 20],
  "current_data_shape": [15000, 20],
  "total_features_monitored": 12,
  "features_with_drift": 4,
  "drift_ratio": 0.33,
  "drift_threshold": 0.3,
  "needs_retrain": true,
  "feature_statistics": {
    "size": {
      "test": "kolmogorov_smirnov",
      "statistic": 0.045,
      "p_value": 0.023,
      "drift_detected": true
    },
    ...
  }
}
```

---

## üîÑ L√≥gica de Reentrenamiento

### Flujo Condicional

```
Datos Nuevos
     ‚îÇ
     ‚ñº
Detectar Drift
     ‚îÇ
     ‚îú‚îÄ‚Üí Drift > 30%? ‚îÄ‚Üí S√ç ‚îÄ‚Üí Optimizar Hyperparams ‚îÄ‚Üí Entrenar ‚îÄ‚Üí Guardar
     ‚îÇ                                                                   ‚îÇ
     ‚îî‚îÄ‚Üí Drift ‚â§ 30%? ‚îÄ‚Üí NO ‚îÄ‚Üí Usar Modelo Existente ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                         ‚îÇ
                                                                         ‚ñº
                                                              Generar Predicciones
```

### Ventajas del Enfoque

1. **Eficiencia:** No reentrenamos innecesariamente
2. **Recursos:** Ahorramos tiempo y c√≥mputo
3. **Estabilidad:** Modelo solo cambia cuando es necesario
4. **Trazabilidad:** Cada decisi√≥n est√° documentada en drift reports

### Consideraciones de Producci√≥n

En un entorno productivo, adem√°s se considerar√≠a:
- **Performance monitoring:** Monitorear m√©tricas del modelo en datos nuevos
- **Drift gradual:** Acumulaci√≥n de drift leve a lo largo del tiempo
- **Reentrenamiento peri√≥dico:** Incluso sin drift, reentrenar cada N semanas
- **A/B testing:** Comparar modelo nuevo vs existente antes de deployment

---

## üî¨ Integraci√≥n con MLflow

### Configuraci√≥n

**Tracking URI:** `file:///path/to/mlruns`
**M√≥dulo:** `mlflow_config.py`

### Experimentos Trackeados

1. **Optimizaci√≥n de Hiperpar√°metros**
   - Experimento: `sodai_drinks_prediction_optimization_{timestamp}`
   - Runs: 1 parent + 50 child runs (uno por trial)
   - Logged:
     - Par√°metros de cada trial
     - M√©tricas: val_recall, val_precision, val_f1, val_auc_pr
     - Gr√°ficos de Optuna (optimization history, param importances)

2. **Modelo Final**
   - Experimento: `sodai_drinks_prediction_final_model_{timestamp}`
   - Logged:
     - Mejores hiperpar√°metros
     - M√©tricas de train y validation
     - Classification report
     - Confusion matrix
     - Precision-Recall curve
     - SHAP plots
     - Modelo completo (pipeline)

### Acceso a MLflow UI

```bash
# Desde el directorio del proyecto
cd Proyecto/entrega2/airflow
mlflow ui --backend-store-uri file:///C:/Users/fmarq/DCC/MDS/MDS7202_Laboratorio/MDS7202_Free_Riders/Proyecto/entrega2/airflow/mlruns

# Acceder en navegador
http://localhost:5000
```

### Recuperaci√≥n de Modelos

```python
from mlflow_config import load_model_from_mlflow

# Cargar mejor modelo del experimento
model = load_model_from_mlflow("sodai_drinks_prediction")
```

---

## üìÅ Estructura de Archivos

```
Proyecto/entrega2/airflow/
‚îÇ
‚îú‚îÄ‚îÄ dags/                           # DAGs y m√≥dulos de Airflow
‚îÇ   ‚îú‚îÄ‚îÄ dag.py                      # DAG principal ‚≠ê
‚îÇ   ‚îú‚îÄ‚îÄ load_and_preprocess.py      # M√≥dulo de preprocesamiento
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py                 # Feature engineering y splitting
‚îÇ   ‚îú‚îÄ‚îÄ drift_detector.py           # Detecci√≥n de drift ‚≠ê
‚îÇ   ‚îú‚îÄ‚îÄ train_module.py             # Entrenamiento con Optuna + MLflow ‚≠ê
‚îÇ   ‚îú‚îÄ‚îÄ predict_module.py           # Generaci√≥n de predicciones
‚îÇ   ‚îî‚îÄ‚îÄ mlflow_config.py            # Configuraci√≥n de MLflow
‚îÇ
‚îú‚îÄ‚îÄ data/                           # Datos
‚îÇ   ‚îú‚îÄ‚îÄ raw/                        # Datos raw (input)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clientes.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ productos.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transacciones.parquet
‚îÇ   ‚îú‚îÄ‚îÄ processed/                  # Datos procesados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ final_data.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_data.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val_data.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_data.parquet
‚îÇ   ‚îî‚îÄ‚îÄ backup/                     # Backups (generados por generate_test_data.py)
‚îÇ
‚îú‚îÄ‚îÄ mlruns/                         # MLflow tracking (generado autom√°ticamente)
‚îÇ   ‚îî‚îÄ‚îÄ 0/
‚îÇ       ‚îî‚îÄ‚îÄ {run_id}/
‚îÇ           ‚îú‚îÄ‚îÄ artifacts/
‚îÇ           ‚îú‚îÄ‚îÄ metrics/
‚îÇ           ‚îú‚îÄ‚îÄ params/
‚îÇ           ‚îî‚îÄ‚îÄ tags/
‚îÇ
‚îú‚îÄ‚îÄ models/                         # Modelos guardados localmente
‚îÇ   ‚îî‚îÄ‚îÄ best_model.pkl
‚îÇ
‚îú‚îÄ‚îÄ predictions/                    # Predicciones generadas
‚îÇ   ‚îî‚îÄ‚îÄ predictions_{date}.parquet
‚îÇ
‚îú‚îÄ‚îÄ drift_reports/                  # Reportes de drift
‚îÇ   ‚îî‚îÄ‚îÄ drift_report_{date}.json
‚îÇ
‚îú‚îÄ‚îÄ generate_test_data.py           # Script para generar datos de prueba ‚≠ê
‚îú‚îÄ‚îÄ README.md                       # Esta documentaci√≥n ‚≠ê
‚îú‚îÄ‚îÄ VIDEO_GUIDE.md                  # Gu√≠a para grabar video ‚≠ê
‚îî‚îÄ‚îÄ requirements.txt                # Dependencias Python

‚≠ê = Archivos clave
```

---

## üõ†Ô∏è Instalaci√≥n y Configuraci√≥n

### Requisitos

- **Python:** 3.9+
- **Sistema Operativo:** Windows, Linux, macOS
- **RAM:** M√≠nimo 8GB (recomendado 16GB)
- **Espacio en disco:** ~5GB

---

## üê≥ Instalaci√≥n con Docker (RECOMENDADO)

**Ventajas:**
- ‚úÖ Setup en un solo comando
- ‚úÖ No requiere configuraci√≥n manual de Airflow
- ‚úÖ Ambiente aislado y reproducible
- ‚úÖ Funciona igual en todas las plataformas
- ‚úÖ Incluye MLflow UI autom√°ticamente

### Prerrequisitos

- **Docker Desktop** instalado ([Descargar aqu√≠](https://www.docker.com/products/docker-desktop/))
- **Docker Compose** (incluido con Docker Desktop)
- **4-8GB RAM** asignados a Docker

### Instalaci√≥n R√°pida

```bash
# 1. Navegar al directorio del proyecto
cd C:\Users\fmarq\DCC\MDS\MDS7202_Laboratorio\MDS7202_Free_Riders\Proyecto\entrega2\airflow

# 2. Iniciar todos los servicios (primera vez puede tardar 5-10 minutos)
docker-compose up -d

# 3. Ver logs en tiempo real (opcional)
docker-compose logs -f

# 4. Esperar a que los servicios est√©n saludables (~60 segundos)
docker-compose ps
```

### Acceso a Interfaces

Una vez iniciado:

- **Airflow UI**: http://localhost:8080
  - Usuario: `admin`
  - Contrase√±a: `admin`

- **MLflow UI**: http://localhost:5000

### Comandos √ötiles

```bash
# Ver estado de servicios
docker-compose ps

# Ver logs de un servicio espec√≠fico
docker-compose logs airflow
docker-compose logs mlflow

# Ejecutar comando dentro del contenedor
docker-compose exec airflow bash

# Detener servicios (mantiene datos)
docker-compose stop

# Iniciar servicios detenidos
docker-compose start

# Detener y remover contenedores (mantiene datos en vol√∫menes)
docker-compose down

# Limpiar TODO (incluye vol√∫menes - cuidado!)
docker-compose down -v

# Reconstruir imagen (despu√©s de cambios en Dockerfile)
docker-compose build
docker-compose up -d
```

### Generar Datos de Prueba (con Docker)

```bash
# Ejecutar script dentro del contenedor
docker-compose exec airflow python generate_test_data.py --mode add_weeks --weeks 2 --noise 0.3

# O desde el host (si Python instalado localmente)
python generate_test_data.py --mode add_weeks --weeks 2 --noise 0.3
```

### Estructura de Vol√∫menes

Los siguientes directorios persisten incluso si destruyes los contenedores:

- `./data/` - Datos raw y procesados
- `./models/` - Modelos entrenados
- `./predictions/` - Predicciones generadas
- `./drift_reports/` - Reportes de drift
- `sodai_mlflow_data` - Experimentos de MLflow (volumen Docker)
- `sodai_postgres_data` - Base de datos de Airflow (volumen Docker)

### Troubleshooting Docker

**Problema: Puerto 8080 ya en uso**
```bash
# Cambiar puerto en docker-compose.yml
ports:
  - "8081:8080"  # Cambia 8080 a 8081
```

**Problema: Contenedores no inician**
```bash
# Ver logs detallados
docker-compose logs

# Verificar recursos de Docker Desktop
# Docker Desktop ‚Üí Settings ‚Üí Resources ‚Üí Aumentar RAM
```

**Problema: Cambios en DAGs no se reflejan**
```bash
# Los DAGs est√°n montados como volumen, cambios son inmediatos
# Si no se reflejan, refrescar Airflow UI o esperar 30 segundos
```

**Problema: "Error creating bean with name 'entityManagerFactory'"**
```bash
# Limpiar y reiniciar
docker-compose down -v
docker-compose up -d
```

---

## üì¶ Instalaci√≥n Manual (Sin Docker)

Si prefieres no usar Docker, puedes instalar manualmente:

### 1. Instalar Dependencias

```bash
# Navegar al directorio del proyecto
cd Proyecto/entrega2/airflow

# Instalar con pip
pip install -r requirements.txt

# O con pyproject.toml (si usas Poetry)
poetry install
```

### 2. Configurar Airflow

```bash
# Inicializar base de datos de Airflow
airflow db init

# Crear usuario admin
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com \
    --password admin

# Configurar AIRFLOW_HOME (opcional)
export AIRFLOW_HOME=/path/to/Proyecto/entrega2/airflow
```

### 3. Configurar Variables de Entorno

Crear archivo `.env` (opcional):

```bash
MLFLOW_TRACKING_URI=file:///C:/path/to/mlruns
AIRFLOW_HOME=/path/to/airflow
```

### 4. Verificar Instalaci√≥n

```bash
# Verificar versi√≥n de Airflow
airflow version

# Verificar DAGs
airflow dags list

# Deber√≠a aparecer: sodai_prediction_pipeline
```

---

## üöÄ Ejecuci√≥n del Pipeline

### Opci√≥n 1: Airflow UI (Recomendado)

#### 1. Iniciar Airflow

```bash
# Terminal 1: Scheduler
airflow scheduler

# Terminal 2: Webserver
airflow webserver --port 8080
```

#### 2. Acceder a UI

Abrir navegador: `http://localhost:8080`

- **Usuario:** admin
- **Contrase√±a:** admin

#### 3. Activar y Ejecutar DAG

1. Buscar `sodai_prediction_pipeline` en la lista
2. Toggle el switch para activarlo (de OFF a ON)
3. Click en el nombre del DAG
4. Click en el bot√≥n "Trigger DAG" (icono ‚ñ∂Ô∏è)
5. Confirmar ejecuci√≥n

#### 4. Monitorear Ejecuci√≥n

- **Graph View:** Visualizaci√≥n del flujo
- **Grid View:** Historial de ejecuciones
- **Logs:** Click en cualquier tarea ‚Üí "Log"

### Opci√≥n 2: L√≠nea de Comandos

```bash
# Ejecutar DAG manualmente
airflow dags trigger sodai_prediction_pipeline

# Ver estado
airflow dags list-runs -d sodai_prediction_pipeline

# Ver logs de una tarea espec√≠fica
airflow tasks logs sodai_prediction_pipeline train_model {execution_date}
```

### Opci√≥n 3: Programaci√≥n Autom√°tica

Modificar en `dag.py`:

```python
# Cambiar schedule_interval
schedule_interval='@weekly'  # Cada lunes a medianoche

# O con cron
schedule_interval='0 0 * * 1'  # Cada lunes a 00:00
```

---

## üß™ Generaci√≥n de Datos de Prueba

Para demostrar el pipeline funcionando (especialmente para el video), usa el script `generate_test_data.py`.

### Modos Disponibles

#### 1. Agregar Nuevas Semanas (Recomendado para Demo)

Simula la llegada de datos nuevos agregando semanas al dataset:

```bash
python generate_test_data.py --mode add_weeks --weeks 2 --noise 0.15
```

**Par√°metros:**
- `--weeks`: N√∫mero de semanas a agregar (default: 1)
- `--noise`: Factor de ruido 0-1 (default: 0.1)

**Qu√© hace:**
- Hace backup de datos originales
- Toma transacciones de semanas recientes
- Crea nuevas semanas con datos similares pero con ruido
- Guarda datos actualizados

#### 2. Muestrear Datos Existentes

Reduce el tama√±o del dataset (√∫til para pruebas r√°pidas):

```bash
python generate_test_data.py --mode sample --sample_frac 0.5 --noise 0.1
```

**Par√°metros:**
- `--sample_frac`: Fracci√≥n de datos a mantener (0-1)
- `--noise`: Factor de ruido

#### 3. Generar Datos Sint√©ticos

Crea datos completamente sint√©ticos:

```bash
python generate_test_data.py --mode synthetic --n_transactions 5000
```

#### 4. Restaurar Datos Originales

Vuelve a los datos iniciales:

```bash
python generate_test_data.py --mode restore
```

#### 5. Ver Resumen de Datos

```bash
python generate_test_data.py --mode summary
```

### Workflow Recomendado para Video

```bash
# 1. Ver datos actuales
python generate_test_data.py --mode summary

# 2. Agregar 2 nuevas semanas con ruido considerable
python generate_test_data.py --mode add_weeks --weeks 2 --noise 0.3

# 3. Ver nuevos datos
python generate_test_data.py --mode summary

# 4. Ejecutar pipeline en Airflow
# (El drift detector deber√≠a detectar cambios y triggear reentrenamiento)

# 5. Despu√©s del video, restaurar datos originales
python generate_test_data.py --mode restore
```

---

## üìä Resultados y Outputs

### 1. Datos Procesados

**Ubicaci√≥n:** `data/processed/`

- **final_data.parquet:** Datos completos (universo cliente-producto-semana)
- **train_data.parquet:** 70% para entrenamiento
- **val_data.parquet:** 15% para validaci√≥n
- **test_data.parquet:** 15% para testing

**Columnas:**
- customer_id, product_id, week
- customer_type, X, Y, num_deliver_per_week, num_visit_per_week
- brand, category, sub_category, segment, package, size
- recency, frequency, customer_product_share, trend
- cluster (geogr√°fico)
- bought (variable objetivo)

### 2. Reportes de Drift

**Ubicaci√≥n:** `drift_reports/drift_report_{date}.json`

**Contenido:**
```json
{
  "timestamp": "2024-11-05T14:30:00",
  "needs_retrain": true,
  "drift_ratio": 0.42,
  "features_with_drift": 5,
  "feature_statistics": {
    "recency": {
      "test": "kolmogorov_smirnov",
      "p_value": 0.001,
      "drift_detected": true
    }
  }
}
```

### 3. Modelos

**MLflow:**
- Experiments: `sodai_drinks_prediction_*`
- Artifacts: Modelos, plots, m√©tricas

**Local:**
- `models/best_model.pkl`: Mejor modelo entrenado

### 4. Predicciones

**Ubicaci√≥n:** `predictions/predictions_{date}.parquet`

**Columnas:**
- `customer_id`: ID del cliente
- `product_id`: ID del producto
- `week`: Semana predicha (√∫ltima semana + 1)
- `prediction`: 0 (no compra) o 1 (compra)
- `probability`: Probabilidad de compra (0-1)

**Ejemplo:**
```
customer_id | product_id | week | prediction | probability
------------|------------|------|------------|------------
1001        | 5234       | 45   | 1          | 0.78
1001        | 5235       | 45   | 0          | 0.12
1002        | 5234       | 45   | 1          | 0.92
```

### 5. M√©tricas en MLflow

**Training:**
- train_accuracy, train_precision, train_recall, train_f1, train_auc_pr

**Validation:**
- val_accuracy, val_precision, val_recall, val_f1, val_auc_pr

**Gr√°ficos:**
- Confusion Matrix
- Precision-Recall Curve
- SHAP Summary Plot
- SHAP Feature Importance
- Optuna Optimization History
- Optuna Parameter Importances

---

## üè≠ Consideraciones de Producci√≥n

### Escalabilidad

**Datos Grandes:**
- Usar Spark para preprocesamiento
- Sampling estrat√©gico para SHAP
- Paralelizar Optuna trials con Dask

**M√∫ltiples Modelos:**
- Task Group para entrenar varios modelos en paralelo
- Comparar performance y seleccionar mejor

### Monitoring

**M√©tricas a Monitorear:**
- Tiempo de ejecuci√≥n de cada tarea
- Performance del modelo en producci√≥n
- Tasa de drift detection
- Uso de recursos (CPU, RAM)

**Alertas:**
- Fallo de tareas cr√≠ticas
- Drift detectado
- Performance del modelo degrada

### Mejoras Futuras

1. **Datos Incrementales:**
   - Solo procesar datos nuevos
   - Merge con datos hist√≥ricos

2. **Modelo Challenger:**
   - Entrenar modelo nuevo en paralelo
   - A/B testing antes de reemplazar

3. **Feature Store:**
   - Centralizar features pre-computadas
   - Reutilizar entre train y predict

4. **Deployment Automatizado:**
   - CI/CD con GitHub Actions
   - Deploy autom√°tico a producci√≥n si m√©tricas OK

5. **Retrain Triggers Adicionales:**
   - Performance degradation
   - Calendario (cada N semanas)
   - Eventos externos (campa√±as)

---

## üìû Contacto y Soporte

**Equipo:** Free Riders

**Miembros:**
- [Nombre 1] - [email@ejemplo.com]
- [Nombre 2] - [email@ejemplo.com]
- [Nombre 3] - [email@ejemplo.com]

**Repositorio:** [GitHub URL]

**Profesor:** [Nombre del Profesor]
**Curso:** MDS7202 - Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos
**Universidad:** [Universidad]
**Semestre:** 2024-2

---

## üìú Referencias

- [Airflow Documentation](https://airflow.apache.org/docs/)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Optuna Documentation](https://optuna.readthedocs.io/)
- [SHAP Documentation](https://shap.readthedocs.io/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)

---

**√öltima Actualizaci√≥n:** Noviembre 2024
**Versi√≥n:** 1.0
