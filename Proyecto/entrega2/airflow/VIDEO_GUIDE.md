# Gu√≠a para Grabaci√≥n del Video - Pipeline de Airflow

**Entrega 2 - MDS7202**
**Equipo:** Free Riders

---

## üìã Requisitos del Video

Seg√∫n el enunciado, el video debe:

‚úÖ Mostrar la ejecuci√≥n del pipeline de Airflow **de principio a fin**
‚úÖ Ejecutar con un **nuevo conjunto de datos** de entrada
‚úÖ Mostrar c√≥mo los datos pasan por la **etapa de reentrenamiento**
‚úÖ Subir a YouTube u otra plataforma y compartir link (no subirlo al repositorio)

**Duraci√≥n recomendada:** 5-10 minutos

---

## üé¨ Estructura del Video

### Secci√≥n 1: Introducci√≥n (30-60 seg)
- Presentaci√≥n del equipo
- Descripci√≥n breve del proyecto
- Objetivo del pipeline

### Secci√≥n 2: Preparaci√≥n de Datos (1-2 min)
- Mostrar datos actuales
- Generar nuevos datos de prueba
- Explicar qu√© cambios se introdujeron

### Secci√≥n 3: Ejecuci√≥n del DAG (3-5 min)
- Iniciar Airflow
- Activar y ejecutar el DAG
- Mostrar progreso de cada tarea
- Explicar qu√© hace cada paso

### Secci√≥n 4: Resultados (2-3 min)
- Mostrar drift report
- Mostrar que se reentren√≥ el modelo
- Mostrar predicciones generadas
- Mostrar experimentos en MLflow

### Secci√≥n 5: Cierre (30 seg)
- Resumen de lo demostrado
- Conclusiones

---

## üõ†Ô∏è Preparaci√≥n Antes de Grabar

### 1. Verificar Instalaci√≥n

```bash
# Verificar Python y paquetes
python --version
pip list | grep airflow
pip list | grep mlflow

# Verificar que el DAG est√° registrado
airflow dags list | grep sodai
```

### 2. Limpiar Estado Anterior

```bash
# Detener Airflow si est√° corriendo
# Ctrl+C en las terminales de scheduler y webserver

# Limpiar runs anteriores (opcional, para video limpio)
rm -rf mlruns/*
rm -rf drift_reports/*
rm -rf predictions/*

# Reinicializar DB de Airflow
airflow db reset
airflow db init

# Recrear usuario
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com \
    --password admin
```

### 3. Preparar Ventanas

Tener abiertas y organizadas:
- **Ventana 1:** Terminal para comandos
- **Ventana 2:** Navegador con Airflow UI (http://localhost:8080)
- **Ventana 3:** Navegador con MLflow UI (http://localhost:5000) - opcional
- **Ventana 4:** Explorador de archivos mostrando carpeta del proyecto

---

## üé• Script de Grabaci√≥n Paso a Paso

### SECCI√ìN 1: Introducci√≥n (GRABANDO)

**[Pantalla: Terminal o presentaci√≥n con t√≠tulo]**

```
üé§ NARRACI√ìN:
"Hola, somos el equipo Free Riders y les presentamos nuestro pipeline
automatizado de Machine Learning para predicci√≥n de compras de productos.

Este pipeline utiliza Apache Airflow para orquestar todo el flujo, desde
la extracci√≥n de datos hasta la generaci√≥n de predicciones. Incluye
detecci√≥n autom√°tica de drift y reentrenamiento condicional del modelo.

Utilizamos MLflow para tracking de experimentos, Optuna para optimizaci√≥n
de hiperpar√°metros, y SHAP para interpretabilidad."
```

---

### SECCI√ìN 2: Preparaci√≥n de Datos

#### Paso 1: Mostrar Datos Actuales

**[Pantalla: Terminal]**

```bash
# Navegar al directorio
cd C:/Users/fmarq/DCC/MDS/MDS7202_Laboratorio/MDS7202_Free_Riders/Proyecto/entrega2/airflow

# Mostrar resumen de datos actuales
python generate_test_data.py --mode summary
```

**[Mostrar output en pantalla]**

```
üé§ NARRACI√ìN:
"Primero, vamos a ver el estado actual de nuestros datos. Como pueden ver,
tenemos X clientes, Y productos, y Z transacciones.

Las transacciones van desde la semana [primera semana] hasta la semana
[√∫ltima semana]."
```

#### Paso 2: Generar Nuevos Datos

**[Pantalla: Terminal]**

```bash
# Generar 2 nuevas semanas con ruido considerable
python generate_test_data.py --mode add_weeks --weeks 2 --noise 0.3
```

**[Mostrar output del script]**

```
üé§ NARRACI√ìN:
"Ahora vamos a simular la llegada de datos nuevos. Agregamos 2 semanas
adicionales de transacciones con un factor de ruido del 30% para
introducir variabilidad.

Esto har√° backup de los datos originales y crear√° nuevas transacciones
basadas en patrones recientes pero con variaciones aleatorias.

[ESPERAR A QUE TERMINE]

Como pueden ver, se agregaron [N] nuevas transacciones. Ahora tenemos
datos hasta la semana [nueva √∫ltima semana]."
```

#### Paso 3: Verificar Nuevos Datos

```bash
# Ver resumen actualizado
python generate_test_data.py --mode summary
```

```
üé§ NARRACI√ìN:
"Perfecto, ahora tenemos nuestro nuevo conjunto de datos que simula la
llegada de informaci√≥n de las siguientes semanas."
```

---

### SECCI√ìN 3: Ejecuci√≥n del DAG

#### Paso 1: Iniciar Airflow

**OPCI√ìN A: Con Docker (RECOMENDADO) üê≥**

**[Pantalla: Terminal]**

```bash
# Navegar al directorio
cd C:/Users/fmarq/DCC/MDS/MDS7202_Laboratorio/MDS7202_Free_Riders/Proyecto/entrega2/airflow

# Iniciar todos los servicios con un solo comando
docker-compose up -d

# Ver logs en tiempo real (opcional)
docker-compose logs -f
```

```
üé§ NARRACI√ìN:
"Iniciamos el pipeline completo con Docker. Con un solo comando,
docker-compose levanta Airflow, MLflow y PostgreSQL.

[ESPERAR ~30-60 segundos]

Los servicios est√°n arrancando. Docker est√° creando los contenedores,
inicializando la base de datos de Airflow, y creando el usuario admin
autom√°ticamente.

[Mostrar docker-compose ps para ver el estado]

Perfecto, todos los servicios est√°n saludables. Ahora accedemos a la
interfaz web en localhost:8080."
```

**OPCI√ìN B: Sin Docker (Manual)**

**[Pantalla: Terminal 1]**

```bash
# Terminal 1: Iniciar Scheduler
airflow scheduler
```

**[SPLIT SCREEN - Pantalla: Terminal 2]**

```bash
# Terminal 2: Iniciar Webserver
airflow webserver --port 8080
```

```
üé§ NARRACI√ìN:
"Iniciamos Airflow manualmente. El scheduler coordina la ejecuci√≥n de las tareas, y
el webserver nos da la interfaz gr√°fica para monitorear el pipeline.

[ESPERAR ~10-15 segundos hasta que inicie]

Ahora accedemos a la interfaz web en localhost:8080."
```

#### Paso 2: Acceder a Airflow UI

**[Pantalla: Navegador - http://localhost:8080]**

```
üé§ NARRACI√ìN:
"Aqu√≠ est√° la interfaz de Airflow. Vamos a buscar nuestro DAG llamado
'sodai_prediction_pipeline'."
```

**[Acciones en video:]**
1. Login con admin/admin (si es necesario)
2. Buscar "sodai" en la barra de b√∫squeda
3. Localizar el DAG

#### Paso 3: Explicar Estructura del DAG

**[Pantalla: Click en el nombre del DAG ‚Üí Tab "Graph"]**

```
üé§ NARRACI√ìN:
"Este es el grafo de nuestro DAG. Como pueden ver, el flujo es:

1. START: Inicio del pipeline
2. EXTRACT NEW DATA: Validaci√≥n de datos raw
3. PREPROCESS DATA: Limpieza y transformaci√≥n
4. SPLIT DATA: Divisi√≥n temporal en train/val/test
5. DETECT DRIFT: An√°lisis estad√≠stico de cambios en distribuciones
6. DECIDE RETRAIN: Branching decision

En este punto, el flujo se divide:
- Si hay drift significativo ‚Üí TRAIN MODEL (optimizaci√≥n + entrenamiento)
- Si no hay drift ‚Üí SKIP RETRAIN (usar modelo existente)

Ambas ramas convergen en:
7. GENERATE PREDICTIONS: Predicciones para pr√≥xima semana
8. END: Fin del pipeline"
```

#### Paso 4: Activar y Ejecutar el DAG

**[Acciones en video:]**

1. **Activar el DAG:**
   - Toggle el switch de OFF a ON

2. **Trigger manual:**
   - Click en el bot√≥n "Trigger DAG" (icono ‚ñ∂Ô∏è en la derecha)
   - Confirmar la ejecuci√≥n

```
üé§ NARRACI√ìN:
"Vamos a activar el DAG y ejecutarlo manualmente. Click en 'Trigger DAG'
y confirmamos.

[ESPERAR A QUE EMPIECE]

Excelente, la ejecuci√≥n ha comenzado. Podemos ver el estado en tiempo real."
```

#### Paso 5: Monitorear Ejecuci√≥n

**[Pantalla: Tab "Graph" o "Grid"]**

**Mientras se ejecuta, ir narrando:**

```
üé§ NARRACI√ìN POR TAREA:

[CUANDO START ‚Üí SUCCESS]
"El pipeline ha iniciado correctamente."

[CUANDO EXTRACT_NEW_DATA est√° running/success]
"La tarea de extracci√≥n est√° validando que los datos existan.
[Si quieres, click en la tarea ‚Üí Log para mostrar los logs brevemente]
Como pueden ver, detect√≥ los 3 archivos parquet: clientes, productos y
transacciones."

[CUANDO PREPROCESS_DATA est√° running]
"Ahora comienza el preprocesamiento. Esta tarea:
- Carga los datos raw
- Limpia transacciones (elimina duplicados, filtra items inv√°lidos)
- Optimiza tipos de datos para eficiencia
- Crea la variable temporal 'week'
- Genera el universo completo de cliente √ó producto √ó semana

[Opcional: mostrar log brevemente]
Esta tarea puede tomar 30-60 segundos dependiendo del volumen de datos."

[CUANDO SPLIT_DATA est√° running]
"La divisi√≥n de datos respeta el orden temporal. 70% para entrenamiento,
15% validaci√≥n, y 15% test. Esto previene data leakage."

[CUANDO DETECT_DRIFT est√° running - IMPORTANTE]
"Esta es una de las tareas clave: la detecci√≥n de drift.

El sistema compara las distribuciones estad√≠sticas de los datos nuevos
contra los datos hist√≥ricos de entrenamiento.

Utiliza:
- Test de Kolmogorov-Smirnov para variables num√©ricas
- Test Chi-cuadrado para variables categ√≥ricas

Si m√°s del 30% de las features monitoreadas muestran drift significativo,
se activa el reentrenamiento.

[Mostrar el log cuando termine para ver el resultado]
```

**[Click en detect_drift ‚Üí Logs cuando termine]**

```
üé§ NARRACI√ìN:
"Veamos el reporte de drift...

[LEER DEL LOG]
Como pueden ver, se detect√≥ drift en [X] de [Y] features monitoreadas.
El ratio de drift es [Z]%, que excede el threshold del 30%.

Por lo tanto, la decisi√≥n es: REENTRENAR EL MODELO."
```

```
[CUANDO DECIDE_RETRAIN ‚Üí TRAIN_MODEL (y no skip_retrain)]
"Perfecto, el branching funcion√≥ correctamente. El sistema decidi√≥
reentrenar porque detect√≥ drift significativo."

[CUANDO TRAIN_MODEL est√° running - MUY IMPORTANTE]
"Esta es la tarea m√°s intensiva del pipeline. Aqu√≠ sucede:

1. OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS con Optuna:
   - 50 trials de b√∫squeda
   - Cada trial entrena un modelo XGBoost con diferentes par√°metros
   - Se optimiza para maximizar Recall (detectar compras)

2. ENTRENAMIENTO DEL MODELO FINAL:
   - Se usa el mejor conjunto de hiperpar√°metros encontrados
   - Se aplica feature engineering: clustering geogr√°fico, features RFM
   - Se balancea las clases con scale_pos_weight

3. INTERPRETABILIDAD:
   - Se generan SHAP values para explicar predicciones
   - Se crean gr√°ficos de feature importance

4. TRACKING:
   - Todo se registra en MLflow: m√©tricas, par√°metros, gr√°ficos, modelo

Esta tarea puede tomar entre 15 y 30 minutos con 50 trials de Optuna."
```

**[NOTA: Si el video es muy largo, puedes:]**

**Opci√≥n A:** Hacer fast-forward del entrenamiento
```
üé§ NARRACI√ìN:
"Para no alargar el video, vamos a acelerar esta parte. El entrenamiento
est√° corriendo en segundo plano con los 50 trials de Optuna.

[FAST FORWARD en edici√≥n hasta que termine]

Y listo, el entrenamiento ha terminado despu√©s de [X] minutos."
```

**Opci√≥n B:** Reducir trials para el video
```python
# En dag.py cambiar temporalmente:
N_OPTUNA_TRIALS = 10  # En vez de 50
```

```
[CUANDO GENERATE_PREDICTIONS est√° running]
"Finalmente, generamos las predicciones para la pr√≥xima semana.

Esta tarea:
- Carga el mejor modelo (del entrenamiento o de MLflow)
- Identifica la √∫ltima semana en los datos
- Crea el universo de cliente √ó producto para la semana siguiente
- Genera predicciones con probabilidades
- Guarda los resultados

Esto nos dice, para cada cliente y cada producto, cu√°l es la probabilidad
de que ese cliente compre ese producto la pr√≥xima semana."

[CUANDO END ‚Üí SUCCESS]
"Excelente, el pipeline ha terminado exitosamente. Todas las tareas se
completaron correctamente."
```

---

### SECCI√ìN 4: Resultados

#### Paso 1: Mostrar Drift Report

**[Pantalla: Explorador de archivos ‚Üí drift_reports/]**

```bash
# O desde terminal
cat drift_reports/drift_report_*.json
```

```
üé§ NARRACI√ìN:
"Veamos el reporte de drift generado.

[MOSTRAR JSON en pantalla]

Aqu√≠ podemos ver:
- El timestamp de la detecci√≥n
- Qu√© features mostraron drift
- Los valores de los tests estad√≠sticos
- La decisi√≥n final: needs_retrain = true"
```

#### Paso 2: Mostrar MLflow

**SI USASTE DOCKER:** MLflow ya est√° corriendo en http://localhost:5000 üéâ

**SI NO USASTE DOCKER:**

**[Pantalla: Terminal]**

```bash
# En nueva terminal
cd Proyecto/entrega2/airflow
mlflow ui --backend-store-uri file:///C:/Users/fmarq/DCC/MDS/MDS7202_Laboratorio/MDS7202_Free_Riders/Proyecto/entrega2/airflow/mlruns
```

**[Pantalla: Navegador - http://localhost:5000]**

```
üé§ NARRACI√ìN:
"Ahora veamos los experimentos registrados en MLflow.

[Si usas Docker, mencionar que MLflow UI ya estaba corriendo autom√°ticamente]

[NAVEGAR EN MLFLOW UI]

Aqu√≠ podemos ver:
- Los 50 trials de optimizaci√≥n de Optuna [mostrar tabla de runs]
- Las m√©tricas de cada trial: recall, precision, F1, AUC-PR
- Los hiperpar√°metros probados

[CLICK en el mejor run]

Este fue el mejor trial, con un recall de [X] en validaci√≥n.

[NAVEGAR A ARTIFACTS]

Y aqu√≠ est√°n todos los artefactos guardados:
- El modelo entrenado
- Gr√°ficos de Optuna [mostrar optimization history]
- SHAP plots [mostrar summary plot]
- Confusion matrix
- Precision-Recall curve"
```

#### Paso 3: Mostrar Predicciones

**[Pantalla: Python/Pandas o Excel]**

```python
# En terminal Python o notebook
import pandas as pd

preds = pd.read_parquet('predictions/predictions_[fecha].parquet')
print(preds.head(20))
print(f"\nTotal predicciones: {len(preds):,}")
print(f"Predicciones positivas: {(preds['prediction'] == 1).sum():,}")
print(f"Tasa de compra predicha: {(preds['prediction'] == 1).mean():.2%}")

# Top 10 predicciones m√°s probables
print("\nTop 10 compras m√°s probables:")
print(preds.nlargest(10, 'probability')[['customer_id', 'product_id', 'probability']])
```

```
üé§ NARRACI√ìN:
"Y por √∫ltimo, las predicciones generadas.

[MOSTRAR DATAFRAME]

Tenemos [N] predicciones en total, una para cada combinaci√≥n de
cliente-producto para la semana [X].

El modelo predice que [M] de estas combinaciones resultar√°n en compras.

Aqu√≠ vemos las top 10 compras m√°s probables seg√∫n el modelo. Por ejemplo,
el cliente [ID] tiene un [XX]% de probabilidad de comprar el producto [ID]."
```

---

### SECCI√ìN 5: Cierre

**[Pantalla: Resumen o conclusi√≥n]**

```
üé§ NARRACI√ìN:
"Para resumir, demostramos nuestro pipeline completo de Airflow que:

‚úÖ Procesa autom√°ticamente datos nuevos
‚úÖ Detecta drift usando tests estad√≠sticos
‚úÖ Decide de forma inteligente cu√°ndo reentrenar
‚úÖ Optimiza hiperpar√°metros con Optuna
‚úÖ Trackea experimentos en MLflow
‚úÖ Genera interpretabilidad con SHAP
‚úÖ Produce predicciones para la pr√≥xima semana

El sistema est√° dise√±ado para producci√≥n: es robusto, modular, y
completamente automatizable.

Gracias por su atenci√≥n. Somos el equipo Free Riders."
```

---

## üìå Tips para Grabar

### T√©cnicos

1. **Resoluci√≥n:** 1920x1080 (Full HD) m√≠nimo
2. **Software de grabaci√≥n:**
   - OBS Studio (gratis, recomendado)
   - Camtasia
   - Loom
   - Screen Studio (Mac)

3. **Audio:**
   - Usa un micr√≥fono decente (no del laptop)
   - Graba en ambiente silencioso
   - Normaliza audio en edici√≥n

4. **Zoom:**
   - Haz zoom en elementos importantes (especialmente logs y JSON)
   - Usa shortcuts para no mostrar mouse innecesariamente

5. **Edici√≥n:**
   - Corta pausas largas
   - Fast-forward en el entrenamiento del modelo
   - Agrega t√≠tulos/captions para secciones
   - M√∫sica de fondo suave (opcional)

### De Contenido

1. **Ensaya antes de grabar**
   - Haz un dry-run completo
   - Cronometra cada secci√≥n
   - Ten un script escrito

2. **Mant√©n un ritmo √°gil**
   - No te detengas mucho en una sola pantalla
   - Explica mientras haces las acciones
   - Evita silencios largos

3. **Destaca lo importante**
   - La detecci√≥n de drift y decisi√≥n de reentrenamiento
   - El proceso de Optuna
   - Los resultados en MLflow
   - Las predicciones finales

4. **S√© profesional pero accesible**
   - Habla claro y pausado
   - Explica t√©rminos t√©cnicos brevemente
   - Muestra entusiasmo por el proyecto

---

## ‚úÖ Checklist Pre-Grabaci√≥n

- [ ] Airflow instalado y funcionando
- [ ] MLflow instalado y funcionando
- [ ] Datos de prueba generados con `generate_test_data.py`
- [ ] Software de grabaci√≥n configurado
- [ ] Micr√≥fono probado
- [ ] Script de narraci√≥n escrito
- [ ] Dry-run realizado
- [ ] Navegador sin tabs innecesarias
- [ ] Terminal con buen contraste (fondo oscuro, texto claro)
- [ ] Notificaciones del sistema desactivadas
- [ ] Todo lo dem√°s cerrado (Slack, email, etc.)

---

## üì§ Despu√©s de Grabar

1. **Editar:**
   - Cortar partes lentas
   - Agregar t√≠tulos de secci√≥n
   - Agregar captions si es necesario
   - Normalizar audio

2. **Exportar:**
   - Formato: MP4
   - Codec: H.264
   - Resoluci√≥n: 1920x1080
   - Bitrate: 5-8 Mbps

3. **Subir a YouTube:**
   - Crear cuenta de YouTube si no tienes
   - Subir como "Unlisted" (no p√∫blico, pero accesible por link)
   - T√≠tulo: "Pipeline de Airflow - Predicci√≥n de Compras - Equipo Free Riders"
   - Descripci√≥n: Incluir link al repositorio GitHub

4. **Compartir:**
   - Copiar link del video
   - Agregarlo al README.md
   - Incluirlo en la entrega

---

## üéØ Estructura Recomendada del Video

| Secci√≥n | Duraci√≥n | Contenido Clave |
|---------|----------|-----------------|
| Intro | 0:00 - 0:45 | Presentaci√≥n, objetivo |
| Datos | 0:45 - 2:00 | Generar datos nuevos, explicar cambios |
| DAG | 2:00 - 6:00 | Ejecutar pipeline, explicar cada tarea |
| Drift | 6:00 - 7:00 | Mostrar drift report, decisi√≥n de retrain |
| MLflow | 7:00 - 8:30 | Experimentos, gr√°ficos, modelo |
| Predicciones | 8:30 - 9:00 | Mostrar resultados |
| Cierre | 9:00 - 9:30 | Resumen |

**Total:** ~9-10 minutos

---

## üö® Troubleshooting

### El DAG no aparece en Airflow
```bash
# Verificar que el archivo est√° en dags/
ls dags/dag.py

# Verificar sintaxis
python dags/dag.py

# Refrescar DAGs
airflow dags list-import-errors
```

### El entrenamiento toma mucho tiempo
```python
# Reducir trials temporalmente en dag.py
N_OPTUNA_TRIALS = 10  # En vez de 50
```

### MLflow no muestra experimentos
```bash
# Verificar que mlruns existe
ls mlruns/

# Iniciar con tracking URI correcto
mlflow ui --backend-store-uri file:///[path_completo]/mlruns
```

---

**¬°Buena suerte con el video!** üé¨

*Free Riders Team - MDS7202*
